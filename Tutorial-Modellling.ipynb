{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling with `scikit-learn`\n",
    "\n",
    "In this tutorial, we will learn about basic data modeling (regression only) techniques using the `scikit-learn` library in Python. We will cover two commonly used machine learning models: \n",
    "\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "\n",
    "It is a very broad area for modelling techniques, so we cannot cover all details. But you are able to check more [mateiral](https://scikit-learn.org/stable/tutorial/basic/tutorial.html) later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "\n",
    "We will use the Boston Housing Dataset again! So can you import the dataset by yourself this time? We will try to predict the MEDV based on other variables as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_housing = pd.read_csv(r\".\\datasets\\BostonHousing.csv\")\n",
    "boston_housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, a complete modeling pipeline includes the steps as below:\n",
    "\n",
    "1. Data collection and loading\n",
    "2. Data pre-processing: handling missing values, removing outliers, formulate structural dataset\n",
    "3. Feature extraction/engineering\n",
    "4. Dataset spliting\n",
    "5. Train the model on the training set to ensure the model fit the data\n",
    "6. validate the model on the validate set to tune the \"hyperparameters\"\n",
    "6. Test the model on the test set and report the performance\n",
    "\n",
    "But on this occasion, as a tutorial, we provide a clean dataset and you are not required to do feature engineering. \n",
    "\n",
    "Hence, we will not focus on the step 1-3, although the first three steps are always the most challenging part costing more than 70% of time in a real-world project.\n",
    "\n",
    "## 1. Data Spliting\n",
    "\n",
    "When building a machine learning model, it's crucial to evaluate how well the model performs on unseen data. To do this effectively, we split our dataset into separate parts: a training set, validation set and a testing set.\n",
    "\n",
    "- Typically, we use a larger portion of the data for training and validation (e.g., 80%) and a smaller portion for testing (e.g., 20%).\n",
    "- Validation set can be furhter separated from the training set, but it reduces the number of avaliable samples for trianing!! Normally, we use K-fold cross validation techniques.\n",
    "- This split ensures that we have enough data to train the model while also reserving enough data to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_housing.drop('medv', axis=1)\n",
    "y = boston_housing['medv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "\n",
    "1. Can you check the shape of `X_train`, `X_test`, `y_train` and `y_test`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (404, 13)\n",
      "Shape of X_test:  (102, 13)\n",
      "Shape of y_train:  (404,)\n",
      "Shape of y_test:  (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train and Test the ML model\n",
    "\n",
    "### 2.1 Linear Regression\n",
    "\n",
    "`scikit-learn` includes most of commonly used machine learning models. OLS-based linear regression in `sklearn.linear_model` is one of the simplest examples.\n",
    "\n",
    "Let's import the OLS linear regressor and then instantiate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we could train the model by call `.fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check fitted mdoel's coefficients and the intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medv = -0.11305592398537863*crim + 0.030110464145648223*zn + 0.04038072041333297*indus + 2.7844382035079644*chas + -17.202633391781003*nox + 4.438835199513043*rm + -0.0062963622109808905*age + -1.447865368530779*dis + 0.26242973558508303*rad + -0.010646786275308219*tax + -0.9154562404680713*ptratio + 0.012351334729969164*b + -0.5085714244487934*lstat + 30.246750993923495\n"
     ]
    }
   ],
   "source": [
    "coefficients = lr_model.coef_\n",
    "intercept = lr_model.intercept_\n",
    "\n",
    "variable_names = X.columns\n",
    "model_str = \"medv = \"\n",
    "for i in range(len(coefficients)):\n",
    "    model_str += str(coefficients[i]) + \"*\" + variable_names[i] + \" + \"\n",
    "model_str += str(intercept)\n",
    "print(model_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check OLS linear regression model's performance on the training set:\n",
    "\n",
    "**Note**: We evaluate the model with three common metrics for regression tasks, i.e., R-square score ($R^2$), Mean Squared Error (MSE) and Mean Absolute Error (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the training set:\n",
      "R2 Score:  0.7508856358979672\n",
      "Mean Squared Error:  21.641412753226316\n",
      "Mean Absolute Error:  3.314771626783226\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr_model.predict(X_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_train_pred)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "print(\"OLS-LR Model performance on the training set:\")\n",
    "print(\"R2 Score: \", R2_score_train)\n",
    "print(\"Mean Squared Error: \", mse_train)\n",
    "print(\"Mean Absolute Error: \", mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OLS linear regression, we normally don't need the validation step, becuase it is simple enough and there is no \"hyperparameter\" to tune for model selection. Hence, we directly evaluate the model on the test set.\n",
    "\n",
    "To test the trained model on the test set using the above same metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the test set:\n",
      "R2 Score:  0.6687594935356318\n",
      "Mean Squared Error:  24.291119474973534\n",
      "Mean Absolute Error:  3.189091965887842\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"OLS-LR Model performance on the test set:\")\n",
    "print(\"R2 Score: \", R2_score_test)\n",
    "print(\"Mean Squared Error: \", mse_test)\n",
    "print(\"Mean Absolute Error: \", mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree regressors on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "Let's import random forest regressor and instantiate it. For hyperparameters that can be tuned, click [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 200, max_depth = 5, min_samples_split = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of hyperparameters can be finely tuned for Random Forest regressor. So we really need a validation set to find the \"best\" hyperparameters.\n",
    "\n",
    "Let's start from the simplest way: split another dataset from the training set. (In practice, K-fold cross validation is an usual choice, but due to time limitation we will skip it on this occasion.)\n",
    "\n",
    "#### Quiz\n",
    "\n",
    "1. Split the training set into a new training set and validation set in a proportion 90:10. Name the new training set as `X_new_train`, `X_val`, `y_new_train`, `y_val`. Specify `random_state = 17` to ensure the results are reproducable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train, X_val, y_new_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the random forest on the new training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, min_samples_split=10, n_estimators=200)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regressor.fit(X_new_train, y_new_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check Random Forest regreesor's performance on the validation set and tune the hyperparameter in the Random Forest model specification till you are satisfying with the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the validation set:\n",
      "R2 Score:  0.8730372108028974\n",
      "Mean Squared Error:  6.12985711731928\n",
      "Mean Absolute Error:  1.7600920546203451\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = rf_regressor.predict(X_val)\n",
    "\n",
    "R2_score_val = r2_score(y_val, y_val_pred)\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "print(\"RF Model performance on the validation set:\")\n",
    "print(\"R2 Score: \", R2_score_val)\n",
    "print(\"Mean Squared Error: \", mse_val)\n",
    "print(\"Mean Absolute Error: \", mae_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test the selected model on the test set and report the outcome metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Model performance on the test set:\n",
      "R2 Score:  0.8623367245404001\n",
      "Mean Squared Error:  10.095368791694103\n",
      "Mean Absolute Error:  2.239529165891398\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"RF Model performance on the test set:\")\n",
    "print(\"R2 Score: \", R2_score_test)\n",
    "print(\"Mean Squared Error: \", mse_test)\n",
    "print(\"Mean Absolute Error: \", mae_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
